[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aplicações de Ciência de Dados",
    "section": "",
    "text": "Introdução\nEsta página apresenta aplicações de ciência de dados inspirados em casos reais.",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "01_analise_descritiva.html",
    "href": "01_analise_descritiva.html",
    "title": "1  Análise Descritiva de Dados",
    "section": "",
    "text": "1.1 Base de Dados e Contexto do Estudo\nEste capítulo tem como objetivo apresentar os fundamentos da análise descritiva de dados, explorando conceitos estatísticos básicos e técnicas de visualização amplamente utilizadas em ciência de dados. Ao longo do capítulo, esses conceitos são aplicados a um conjunto de dados reais do setor aéreo, permitindo conectar teoria estatística a problemas práticos de análise e tomada de decisão.\nNesta seção, é apresentado o conjunto de dados utilizado ao longo do capítulo. O pacote {nycflights13} fornece informações detalhadas sobre voos que partiram dos aeroportos de Nova York em 2013, além de dados meteorológicos e características dos aeroportos e aeronaves. A compreensão da estrutura e do contexto desses dados é fundamental para interpretar corretamente as análises realizadas nas seções seguintes. As tabelas disponíves são:\nA análise será feita utilizando a liguagem R. Utilize o código abaixo para carregar o pacote na sua sessão e exibir uma amostra da base que registra os voos, flights.\nlibrary(tidyverse)\n\nset.seed(1)\n\nflights |&gt; \n  slice_sample(n = 5)\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\n\n\n2013\n7\n8\n804\n730\n34\n1043\n1010\n33\nB6\n683\nN809JB\nJFK\nMCO\n129\n944\n7\n30\n2013-07-08 07:00:00\n\n\n2013\n10\n23\n807\n810\n-3\n1102\n1111\n-9\nDL\n1167\nN303DQ\nJFK\nTPA\n158\n1005\n8\n10\n2013-10-23 08:00:00\n\n\n2013\n8\n8\n1258\n1255\n3\n1605\n1606\n-1\nUA\n1700\nN37409\nEWR\nSFO\n341\n2565\n12\n55\n2013-08-08 12:00:00\n\n\n2013\n1\n13\n1813\n1815\n-2\n2036\n1958\n38\n9E\n4019\nN8432A\nJFK\nRIC\n55\n288\n18\n15\n2013-01-13 18:00:00\n\n\n2013\n5\n23\nNA\n1931\nNA\nNA\n2216\nNA\nEV\n4204\nN14117\nEWR\nOKC\nNA\n1325\n19\n31\n2013-05-23 19:00:00",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Análise Descritiva de Dados</span>"
    ]
  },
  {
    "objectID": "01_analise_descritiva.html#base-de-dados-e-contexto-do-estudo",
    "href": "01_analise_descritiva.html#base-de-dados-e-contexto-do-estudo",
    "title": "1  Análise Descritiva de Dados",
    "section": "",
    "text": "flights, que contém informações sobre voos, como horários de partida e chegada, companhias aéreas, destinos e atrasos;\nweather, que fornece dados meteorológicos relacionados aos aeroportos de Nova York durante o ano de 2013;\nairlines, que lista informações sobre as companhias aéreas que operam em Nova York;\nairports, que contém detalhes sobre os aeroportos de Nova York;\nplanes, que oferece dados sobre os aviões utilizados nos voos. Essas tabelas abrangentes permitem uma análise abrangente e detalhada do sistema de transporte aéreo da cidade de Nova York em 2013.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Análise Descritiva de Dados</span>"
    ]
  },
  {
    "objectID": "01_analise_descritiva.html#fundamentos-de-estatística-descritiva",
    "href": "01_analise_descritiva.html#fundamentos-de-estatística-descritiva",
    "title": "1  Análise Descritiva de Dados",
    "section": "1.2 Fundamentos de Estatística Descritiva",
    "text": "1.2 Fundamentos de Estatística Descritiva\nA análise descritiva busca resumir e organizar informações contidas em um conjunto de dados, fornecendo uma visão inicial de seus principais padrões e características. Nesta seção, são apresentados os conceitos fundamentais relacionados aos tipos de variáveis e às principais medidas descritivas, que servirão de base para todas as análises exploratórias realizadas ao longo do capítulo.\n\n1.2.1 Tipos de Variáveis\nAs variáveis em um conjunto de dados podem ser classificadas em diferentes tipos, dependendo da natureza da informação que representam. Existem dois principais tipos de variáveis: qualitativas e quantitativas.\n\nVariáveis Qualitativas\nSão características não numéricas que descrevem qualidades ou atributos dos elementos em estudo. Podem ser subdivididas em:\n\nNominal: Não possuem ordem intrínseca. Exemplos incluem origem (orign: EWR, LGA, JFK) e destino (dest: IAH, MIA, BQN) dos voos.\nOrdinal: Possuem uma ordem intrínseca. Exemplos incluem níveis de classificação ou categorias ordenadas, como faixas de atraso (baixo, médio, alto) ou níveis de prioridade operacional.\n\nVariáveis temporais, como mês e dia, frequentemente ocupam uma posição intermediária, podendo ser tratadas como quantitativas discretas ou categóricas ordenadas, a depender do objetivo da análise.\n\n\nVariáveis Quantitativas\nRepresentam quantidades numéricas mensuráveis. Podem ser subdivididas em contínuas e discretas:\n\nContínua: Podem assumir qualquer valor dentro de um intervalo. Exemplos incluem tempo de voo (air_time) em minutos e distância percorrida (distance) em milhas.\nDiscreta: São contáveis e assumem valores inteiros. Exemplos incluem hora programada da partida (hour) e minuto programado da partida (minute).\n\n\n\n\n1.2.2 Medidas Descritivas\nAs medidas descritivas são ferramentas essenciais para resumir e interpretar as características fundamentais de uma distribuição de dados.\n\nMedidas de Posição:\nAs medidas de posição fornecem informações sobre a localização dos dados dentro da distribuição.\n\nMínimo: O menor valor observado no conjunto de dados.\nMáximo: O maior valor observado no conjunto de dados.\nModa: O valor que ocorre com maior frequência no conjunto de dados.\nMédia: A média aritmética dos valores no conjunto de dados.\nMediana: O valor que separa os dados em duas metades, onde metade dos dados estão abaixo dela e metade acima.\nPercentis: São os valores que dividem uma amostra ordenada em cem partes iguais. O percentil 50 é equivalente à mediana.\n\n\n\nMedidas de Dispersão:\nAs medidas de dispersão indicam o quão espalhados os dados estão em torno da medida de posição central.\n\nAmplitude: A diferença entre o maior e o menor valor no conjunto de dados.\nDistância Interquartil: A diferença entre o terceiro quartil (Q3) e o primeiro quartil (Q1). Ela indica a dispersão dos valores centrais.\nVariância: A média dos quadrados das diferenças entre cada valor e a média.\nDesvio Padrão: A raiz quadrada da variância. Indica a dispersão dos valores em relação à média.\nCoeficiente de Variação: É a razão entre o desvio padrão e a média, expressa como uma porcentagem. Fornece uma medida relativa da variabilidade em relação à magnitude da média.\n\n\n\n\n1.2.3 Resumo estatístico automatizado\nA função skim() do pacote skimr, quando aplicada à uma base de dados, fornece um resumo estatístico das variáveis contidas no dataframe, incluindo contagem de observações, média, desvio padrão, mínimo, máximo e quartis para variáveis numéricas, além da contagem de valores únicos e dos valores mais frequentes para variáveis categóricas.\n\nlibrary(skimr)\n\nskim(flights)\n\n\nData summary\n\n\nName\nflights\n\n\nNumber of rows\n33677\n\n\nNumber of columns\n19\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n4\n\n\nnumeric\n14\n\n\nPOSIXct\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\ncarrier\n0\n1.00\nFALSE\n16\nUA: 5963, EV: 5426, B6: 5403, DL: 4877\n\n\ntailnum\n246\n0.99\nFALSE\n3509\nN71: 60, N71: 54, N72: 54, N72: 49\n\n\norigin\n0\n1.00\nFALSE\n3\nEWR: 12239, JFK: 10917, LGA: 10521\n\n\ndest\n0\n1.00\nFALSE\n99\nATL: 1765, ORD: 1709, LAX: 1601, MCO: 1523\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1.00\n2013.00\n0.00\n2013\n2013\n2013\n2013\n2013\n▁▁▇▁▁\n\n\nmonth\n0\n1.00\n6.53\n3.41\n1\n4\n7\n9\n12\n▇▆▆▆▇\n\n\nday\n0\n1.00\n15.72\n8.79\n1\n8\n16\n23\n31\n▇▇▇▇▆\n\n\ndep_time\n824\n0.98\n1353.50\n488.88\n1\n909\n1408\n1749\n2400\n▁▇▆▇▃\n\n\nsched_dep_time\n0\n1.00\n1349.38\n468.84\n500\n910\n1400\n1730\n2359\n▇▆▇▇▃\n\n\ndep_delay\n824\n0.98\n12.45\n39.93\n-32\n-5\n-1\n11\n1137\n▇▁▁▁▁\n\n\narr_time\n872\n0.97\n1503.77\n536.23\n1\n1105\n1538\n1944\n2400\n▁▃▇▇▇\n\n\nsched_arr_time\n0\n1.00\n1539.85\n499.94\n1\n1125\n1600\n1951\n2359\n▁▃▇▇▇\n\n\narr_delay\n960\n0.97\n6.80\n44.49\n-70\n-17\n-5\n14\n1127\n▇▁▁▁▁\n\n\nflight\n0\n1.00\n1970.27\n1632.59\n1\n561\n1496\n3465\n6181\n▇▅▂▃▁\n\n\nair_time\n960\n0.97\n150.95\n92.77\n22\n83\n130\n192\n667\n▇▃▂▁▁\n\n\ndistance\n0\n1.00\n1041.68\n724.33\n80\n509\n888\n1389\n4983\n▇▃▂▁▁\n\n\nhour\n0\n1.00\n13.23\n4.68\n5\n9\n14\n17\n23\n▇▆▆▇▃\n\n\nminute\n0\n1.00\n26.19\n19.31\n0\n8\n29\n44\n59\n▇▃▆▃▅\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ntime_hour\n0\n1\n2013-01-01 05:00:00\n2013-12-31 21:00:00\n2013-07-02 16:00:00\n6231\n\n\n\n\n\nVeja que a tabela flights indica um conjunto relativamente grande e bem estruturado, com 33.677 observações e 19 variáveis, majoritariamente numéricas, o que é adequado para análises descritivas e exploratórias. As variáveis categóricas apresentam alta completude e diversidade relevante — com três aeroportos de origem, 99 destinos e 16 companhias aéreas — refletindo uma malha aérea ampla e heterogênea. As variáveis de atraso na partida e na chegada exibem médias positivas, mas medianas negativas, evidenciando distribuições assimétricas à direita, nas quais poucos atrasos extremos elevam a média. Observa-se também a presença moderada de valores ausentes, concentrados principalmente em horários e atrasos, o que é consistente com cancelamentos ou registros incompletos. Em conjunto, os dados sugerem boa qualidade geral, variabilidade operacional significativa e potencial para revelar padrões relevantes de pontualidade, sazonalidade e desempenho entre aeroportos e rotas.\n\n\n1.2.4 Visualização de dados\n\nA visualização de dados é essencial na análise de dados, pois transfoma valores em representações visuais claras. Os gráficos facilitam a identificação de padrões e tendências, além de melhorar a comunicação dos resultados, contribuindo para a tomada de decisões informadas.\nOs gráficos apresentados a seguir não têm como objetivo responder perguntas de negócio específicas, mas ilustrar como diferentes tipos de visualizações podem ser utilizados para explorar dados conforme o tipo de variável envolvida.\n\nHistograma\nUm histograma é útil para representar a distribuição de uma variável quantitativa. Ele divide os dados em intervalos e mostra a frequência de observações em cada intervalo.\n\nggplot(flights, aes(x = air_time)) +\n  geom_histogram(binwidth = 30, fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Distribuição do Tempo de Voo\", \n       x = \"Tempo de Voo (minutos)\", \n       y = \"Frequência\")\n\n\n\n\n\n\n\n\n\n\nBoxplot (Gráfico de Caixa)\nUm boxplot é útil para visualizar a distribuição, a mediana e a dispersão dos dados. Ele representa os quartis, a mediana e os possíveis valores discrepantes.\nPor ser um gráfico que contém bastante informação, apresento em detalhes os principais elementos de um boxplot:\n\nCaixa (Box): A caixa do boxplot representa o intervalo interquartil (IQR), que é a distância entre o primeiro quartil (Q1) e o terceiro quartil (Q3). Ela abrange o meio dos dados e mostra onde está localizada a maior parte dos valores.\nLinha Mediana (Mediana): A linha dentro da caixa representa a mediana dos dados, que é o valor que divide o conjunto de dados ao meio.\nWhiskers (Hastes): As hastes que se estendem para fora da caixa, conhecidas como whiskers, mostram a extensão dos dados. Podem ser calculadas de diferentes maneiras, mas geralmente estendem-se até 1,5 vezes o IQR a partir dos quartis.\nOutliers (Valores Atípicos): Valores que estão além das extremidades dos whiskers são considerados outliers e são representados individualmente no gráfico.\nPontos: Além dos outliers, pontos individuais podem ser mostrados no gráfico para representar dados que são excepcionalmente distantes da maioria dos valores.\n\nEsses elementos combinados fornecem uma representação concisa e informativa da distribuição dos dados, destacando medidas de tendência central, variabilidade e presença de valores atípicos.\n\n# Criando um boxplot para a variável \"distance\"\nggplot(flights, aes(y = distance)) +\n  geom_boxplot(fill = \"lightgreen\", color = \"black\") +\n  labs(title = \"Distribuição da Distância dos Voos\", y = \"Distância (milhas)\")\n\n\n\n\n\n\n\n\n\n\nGráfico de Densidade\nUm gráfico de densidade é útil para visualizar a distribuição de uma variável quantitativa de forma suavizada.\n\n# Criando um gráfico de densidade para a variável \"dep_delay\"\nggplot(flights, aes(x = dep_delay)) +\n  geom_density(fill = \"lightcoral\", color = \"black\") +\n  labs(title = \"Densidade do Atraso na Partida\", \n       x = \"Atraso na Partida (minutos)\", \n       y = \"Densidade\")\n\n\n\n\n\n\n\n\n\n\nGráfico de Dispersão\nUm gráfico de dispersão é útil para visualizar a relação entre duas variáveis quantitativas. Ele mostra como uma variável depende da outra.\n\n# Criando um gráfico de dispersão para a relação entre \"air_time\" e \"distance\"\nggplot(flights, aes(x = air_time, y = distance)) +\n  geom_point(color = \"darkorange\", alpha = 0.5) +\n  labs(title = \"Relação entre Tempo de Voo e Distância\", \n       x = \"Tempo de Voo (minutos)\", \n       y = \"Distância (milhas)\")\n\n\n\n\n\n\n\n\n\n\nGráfico de Barras\nUm gráfico de barras é útil para representar a frequência de ocorrência de diferentes categorias em uma variável discreta.\n\n# Criando um gráfico de barras para a variável \"origin\"\nggplot(flights, aes(x = origin)) +\n  geom_bar(fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Frequência de Voos por Origem\", \n       x = \"Origem\", \n       y = \"Frequência\")\n\n\n\n\n\n\n\n\n\n\nGráfico de Setores (Pizza)\nUm gráfico de setores é útil para representar a proporção de cada categoria em relação ao total.\n\n# Criando um gráfico de setores para a variável \"origin\"\nggplot(flights, aes(x = \"\", fill = origin)) +\n  geom_bar(width = 1) +\n  coord_polar(theta = \"y\") +\n  labs(title = \"Proporção de Voos por Destino\", fill = \"Origem\", \n       x = NULL, y = NULL)+\n  scale_fill_manual(values = c(\"EWR\" = \"skyblue\", \n                               \"LGA\" = \"lightgreen\", \n                               \"JFK\" = \"salmon\"))  # Definindo cores personalizadas\n\n\n\n\n\n\n\n\nEmbora gráficos de setores sejam populares, seu uso deve ser criterioso, pois dificultam comparações precisas entre categorias. Em muitos contextos, gráficos de barras oferecem maior clareza.\n\n\nGráfico de Mosaico\nUm gráfico de mosaico é útil para visualizar a relação entre duas variáveis categóricas, mostrando a proporção de cada categoria em cada nível da outra variável.\n\n# Criando um gráfico de mosaico para a relação entre \"origin\" e dia da semana do voo.\n\ndias_pt &lt;- c(\n  \"domingo\",\n  \"segunda-feira\",\n  \"terça-feira\",\n  \"quarta-feira\",\n  \"quinta-feira\",\n  \"sexta-feira\",\n  \"sábado\"\n)\n\nflights |&gt;  \n  mutate(\n    day_of_week = wday(time_hour, label = TRUE, abbr = FALSE, locale = \"Portuguese_Brazil.utf8\"), \n    day_of_week = factor(day_of_week, levels = dias_pt)\n  ) |&gt;\n  ggplot(aes(x = origin, fill = day_of_week)) +\n  geom_bar(position = \"fill\") +\n  labs(\n    title = \"Relação entre Origem e Dia da Semana\",\n    fill = \"Dia da Semana\",\n    x = \"Origem\",\n    y = \"Proporção\"\n  ) +\n  scale_fill_manual(values = RColorBrewer::brewer.pal(7, \"Set2\"))\n\n\n\n\n\n\n\n\n\n\n\n1.2.5 Associação entre Duas Variáveis\nAté este ponto, a análise concentrou-se principalmente em variáveis isoladas, explorando suas distribuições e características individuais. No entanto, muitas perguntas relevantes em ciência de dados envolvem compreender como duas ou mais variáveis se relacionam. A análise de associação permite investigar padrões conjuntos, dependências e possíveis relações entre variáveis, constituindo um passo intermediário entre a exploração descritiva e análises explicativas mais avançadas.\nUm exemplo de análise de associação entre duas variáveis pode ser feito ao contar o número de voos de cada origem para cada destino e selecionar os 5 destinos mais frequentes para cada origem, podemos explorar a associação entre origem e destin O código abaixo fornece os 5 destinos mais frequentes a partir de cada origem, permitindo-nos explorar a associação entre origem e destino de voos.\n\nmost_frequent_dest &lt;- flights |&gt; \n  group_by(origin, dest) |&gt; \n  count() |&gt; \n  arrange(desc(n)) |&gt;  \n  group_by(origin) |&gt;\n  slice_max(n, n = 5)\n\nmost_frequent_dest |&gt; \n  kableExtra::kable()\n\n\n\n\norigin\ndest\nn\n\n\n\n\nEWR\nORD\n622\n\n\nEWR\nMCO\n553\n\n\nEWR\nSFO\n549\n\n\nEWR\nCLT\n516\n\n\nEWR\nBOS\n512\n\n\nJFK\nLAX\n1118\n\n\nJFK\nSFO\n766\n\n\nJFK\nMCO\n591\n\n\nJFK\nBOS\n571\n\n\nJFK\nSJU\n485\n\n\nLGA\nATL\n1065\n\n\nLGA\nORD\n879\n\n\nLGA\nCLT\n646\n\n\nLGA\nMIA\n567\n\n\nLGA\nDFW\n493\n\n\n\n\n\n\n\n\n\n\norigin\ndest\nn\n\n\n\n\nEWR\nORD\n622\n\n\nEWR\nMCO\n553\n\n\nEWR\nSFO\n549\n\n\nEWR\nCLT\n516\n\n\nEWR\nBOS\n512\n\n\nJFK\nLAX\n1118\n\n\nJFK\nSFO\n766\n\n\nJFK\nMCO\n591\n\n\nJFK\nBOS\n571\n\n\nJFK\nSJU\n485\n\n\nLGA\nATL\n1065\n\n\nLGA\nORD\n879\n\n\nLGA\nCLT\n646\n\n\nLGA\nMIA\n567\n\n\nLGA\nDFW\n493\n\n\n\n\n\nAlém da análise tabular, também podemos visualizar os destinos mais frequentes por origem usando um gráfico de barras.\n\n# Gráfico de barras dos destinos mais frequentes por origem\nlibrary(tidytext)\nggplot(most_frequent_dest, aes(x = reorder_within(dest,n,dest), y = n, fill = dest)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_x_reordered() +\n  labs(title = \"Destinos Mais Frequentes por Origem\", \n       x = \"Origem\", \n       y = \"Número de Voos\", \n       fill = \"Destino\") +\n  facet_grid(~origin, scales = \"free_x\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nPodemos investigar se existe alguma relação entre a distância do voo e o atraso médio. Para explorar essa relação, podemos criar um gráfico de dispersão que mostra a distância média em relação ao atraso médio para cada destino.\n\nlibrary(plotly)\ngrafico &lt;- flights |&gt; \n  filter(!is.na(distance), !is.na(arr_delay)) |&gt;\n  group_by(dest) |&gt;\n  summarise(distance = mean(distance),\n            delay = mean(arr_delay)) |&gt; \n  mutate(sinal = ifelse(delay &gt; 0, \"Atrasou\", \"Adiantou\")) |&gt;\n  ggplot(aes(x = distance, y = delay, label = dest, color = sinal))+\n  geom_point() +  \n  scale_color_manual(values = c(\"Adiantou\" = \"lightgreen\", \n                                \"Atrasou\" = \"salmon\")) +  # Definindo cores manualmente\n  labs(title = \"Relação entre Distância Média e Atraso Médio por Destino\", \n       x = \"Distância Média (milhas)\", \n       y = \"Atraso Médio (minutos)\", \n       color = \"Atraso / Adiantamento\")\n\n\n\n\n\n\n\nExercício: quais outras variáveis poderiam ter suas relações exploradas?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Análise Descritiva de Dados</span>"
    ]
  },
  {
    "objectID": "01_analise_descritiva.html#estudo-de-caso-questões-estratégicas-de-negócio",
    "href": "01_analise_descritiva.html#estudo-de-caso-questões-estratégicas-de-negócio",
    "title": "1  Análise Descritiva de Dados",
    "section": "1.3 Estudo de Caso: questões estratégicas de negócio",
    "text": "1.3 Estudo de Caso: questões estratégicas de negócio\nEsta seção propõe um conjunto de questões analíticas com foco em tomada de decisão e interpretação gerencial. Diferentemente das seções anteriores, que tiveram caráter predominantemente ilustrativo, este estudo de caso propõe uma análise orientada por perguntas de negócio. O objetivo é demonstrar como as ferramentas de estatística descritiva e visualização podem ser combinadas para apoiar diagnósticos operacionais e decisões gerenciais em contextos reais.\n\n1.3.1 Questões estratégicas de negócio\nAs questões a seguir têm como objetivo consolidar os conceitos apresentados e estimular o leitor a conduzir uma análise exploratória orientada a decisões de negócio. Para responder às questões, considere agregações por origem, destino e tempo, bem como o uso de visualizações comparativas. Não há uma única abordagem correta.\n\nQuais são os principais gargalos operacionais?\n\nIdentificação de rotas com maiores atrasos, cancelamentos e remanejamentos.\nAlguma rota específica tem consistentemente atrasos elevados?\n\nHá diferenças operacionais entre os três aeroportos de Nova York (JFK, LGA e EWR)?\n\nQual deles apresenta maior índice de atrasos? Quais são os horários mais críticos?\n\nA sazonalidade afeta a operação?\n\nExistem meses ou dias da semana com maior índice de cancelamentos ou atrasos?\n\nComo as condições meteorológicas impactam os voos?\n\nQuais eventos climáticos mais afetam as operações? Neve, tempestades ou ventos fortes?\n\n\n\n\n\n\n\n\nDicaRespostas\n\n\n\n\n\nOs principais achados do estudo de caso estão consolidados abaixo e interpretados à luz de implicações operacionais e estratégicas. O objetivo é destacar como análises descritivas podem apoiar decisões gerenciais, além de discutir limitações e possíveis extensões da análise realizada.\n1. Quais são os principais gargalos operacionais?\nVamos identificar rotas (origem–destino) com maior atraso médio na chegada, considerando apenas rotas com volume relevante de voos.\n\ngargalos_rotas &lt;- flights |&gt;\n  filter(!is.na(arr_delay)) |&gt;\n  group_by(origin, dest) |&gt;\n  summarise(\n    atraso_medio = mean(arr_delay),\n    n_voos = n(),\n    .groups = \"drop\"\n  ) |&gt;\n  filter(n_voos &gt;= 50) |&gt;\n  arrange(desc(atraso_medio))\n\n\n\n\n\n\norigin\ndest\natraso_medio\nn_voos\n\n\n\n\nJFK\nCMH\n49.95312\n64\n\n\nEWR\nRIC\n39.04138\n145\n\n\nEWR\nGRR\n28.03175\n63\n\n\nEWR\nDCA\n26.81111\n180\n\n\nEWR\nDAY\n24.27273\n99\n\n\nEWR\nMKE\n23.02655\n113\n\n\nEWR\nGSO\n22.38144\n97\n\n\nJFK\nCLE\n21.38571\n70\n\n\nEWR\nMEM\n20.93814\n97\n\n\nEWR\nPWM\n20.37313\n67\n\n\n\n\n\nVeja no gráfico abaixo o top 10 rotas com maior atraso médio na chegada.\n\nggplot(\n  gargalos_rotas |&gt; slice_max(atraso_medio, n = 10),\n  aes(x = reorder(paste(origin, dest, sep = \" → \"), atraso_medio),\n      y = atraso_medio)\n) +\n  geom_col(fill = \"salmon\") +\n  coord_flip() +\n  labs(\n    title = \"Rotas com Maior Atraso Médio na Chegada\",\n    x = \"Rota\",\n    y = \"Atraso médio (minutos)\"\n  )\n\n\n\n\n\n\n\n\nNote que os gargalos operacionais não estão distribuídos aleatoriamente, mas concentrados em um conjunto específico de rotas, com destaque para aquelas que partem dos aeroportos de Newark (EWR) e JFK. Em particular, EWR aparece de forma recorrente entre as rotas mais problemáticas, sugerindo a presença de restrições estruturais ou operacionais persistentes. Além disso, observa-se que vários dos maiores atrasos médios ocorrem em rotas de curta ou média distância, o que indica que esses atrasos não são explicados apenas pelo tempo de voo, mas possivelmente por congestionamentos, limitações de capacidade aeroportuária ou atrasos acumulados ainda em solo.\nDo ponto de vista estratégico, os resultados indicam que iniciativas de melhoria operacional devem priorizar rotas específicas, em vez de ações genéricas sobre toda a malha. A recorrência de EWR entre as rotas mais atrasadas sugere a necessidade de uma avaliação aprofundada da capacidade do aeroporto, incluindo alocação de slots, eficiência das operações em solo e sensibilidade a fatores externos, como condições meteorológicas. Intervenções direcionadas nesses pontos têm potencial para gerar ganhos relevantes de pontualidade com custo relativamente controlado.\nAlém disso, o fato de rotas mais curtas apresentarem atrasos elevados aponta para oportunidades de melhoria rápida por meio de ajustes operacionais, como revisão de horários críticos, otimização de processos de embarque e desembarque e melhor coordenação entre companhias aéreas e controle de tráfego aéreo. Essas ações podem reduzir atrasos sem depender de investimentos estruturais de longo prazo, contribuindo diretamente para a melhoria da experiência do passageiro e da eficiência operacional.\nUma vez identificadas as rotas críticas, surge a questão de saber se esses atrasos estão associados a características estruturais da rota ou a práticas operacionais específicas das companhias aéreas.\n\n# Selecionar rotas críticas (top 10)\nrotas_criticas &lt;- gargalos_rotas |&gt;\n  slice_max(atraso_medio, n = 10) |&gt;\n  select(origin, dest)\n\n# Atraso médio por companhia dentro das rotas críticas\natraso_cia_rotas &lt;- flights |&gt;\n  semi_join(rotas_criticas, by = c(\"origin\", \"dest\")) |&gt;\n  filter(!is.na(arr_delay)) |&gt;\n  group_by(origin, dest, carrier) |&gt;\n  summarise(\n    atraso_medio = mean(arr_delay),\n    n_voos = n(),\n    .groups = \"drop\"\n  ) |&gt;\n  filter(n_voos &gt;= 20) |&gt;     # controle de volume\n  arrange(desc(atraso_medio))\n\n# atraso_cia_rotas |&gt;\n#   kableExtra::kable()\n\n\nggplot(\n  atraso_cia_rotas,\n  aes(x = reorder(carrier, atraso_medio),\n      y = atraso_medio,\n      fill = carrier)\n) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  facet_grid(origin + dest ~ ., scales = \"free_y\") +\n  labs(\n    title = \"Atraso Médio por Companhia nas Rotas Críticas\",\n    x = \"Companhia aérea\",\n    y = \"Atraso médio na chegada (minutos)\"\n  )\n\n\n\n\n\n\n\n\nA análise dos atrasos por companhia aérea nas rotas críticas revela que os gargalos observados não são, em sua maioria, de natureza estrutural do aeroporto ou da rota. Em diversas rotas com elevado atraso médio, observa-se forte concentração em uma única companhia aérea, em especial a EV (ExpressJet Airlines), que domina praticamente todas as rotas mais problemáticas a partir de EWR, mesmo quando o número de voos é suficientemente grande para garantir robustez estatística. Além disso, em rotas operadas por mais de uma companhia, como JFK–CLE, o desempenho heterogêneo entre empresas — com 9E (Endeavor Air) apresentando atraso médio substancialmente superior ao da MQ (Envoy Air) — indica que fatores operacionais internos, e não condições aeroportuárias ou da rota, desempenham papel central na geração dos atrasos. Esses resultados sugerem que políticas voltadas exclusivamente à infraestrutura aeroportuária seriam insuficientes para mitigar os atrasos observados, sendo necessária também a consideração de práticas operacionais específicas das companhias aéreas.\n2. Há diferenças operacionais entre os três aeroportos de Nova York (JFK, LGA e EWR)?\n\natraso_origem &lt;- flights |&gt;\n  filter(!is.na(dep_delay)) |&gt;\n  group_by(origin) |&gt;\n  summarise(\n    atraso_medio = mean(dep_delay),\n    mediana = median(dep_delay),\n    .groups = \"drop\"\n  )\n\nVeja na tabela abaixo o atraso médio na partida por aeroporto.\n\n\n\n\n\norigin\natraso_medio\nmediana\n\n\n\n\nEWR\n14.88826\n-1\n\n\nJFK\n11.43401\n-1\n\n\nLGA\n10.67389\n-3\n\n\n\n\n\nA figura a seguir mostra o atraso médio por horário e origem do voo.\n\nflights |&gt;\n  filter(!is.na(dep_delay)) |&gt;\n  mutate(hour = hour(time_hour)) |&gt;\n  group_by(origin, hour) |&gt;\n  summarise(atraso_medio = mean(dep_delay), .groups = \"drop\") |&gt;\n  filter(atraso_medio &gt;= 0) |&gt; \n  ggplot(aes(x = hour, y = atraso_medio)) +\n  geom_col(linewidth = 1, alpha = 0.8) +\n  labs(\n    title = \"Atraso Médio por Horário e Aeroporto\",\n    x = \"Hora do dia\",\n    y = \"Atraso médio (minutos)\"\n  ) +\n  facet_grid(~origin)\n\n\n\n\n\n\n\n\nA análise agregada dos atrasos por aeroporto de origem mostra diferenças claras de desempenho operacional entre os três principais aeroportos de Nova York. O aeroporto de Newark (EWR) apresenta o maior atraso médio na partida (14,9 minutos), seguido por JFK (11,4 minutos) e LaGuardia (LGA), com o menor atraso médio (10,7 minutos). Apesar disso, as medianas negativas em todos os aeroportos indicam que mais da metade dos voos parte no horário ou antecipadamente, o que sugere que os atrasos médios elevados são influenciados por uma cauda de eventos extremos — poucos voos muito atrasados que puxam a média para cima.\nA análise por horário do dia revela um padrão consistente de deterioração operacional ao longo do dia, caracterizando um forte efeito de propagação de atrasos. Nos três aeroportos, os voos realizados nas primeiras horas da manhã apresentam atrasos médios próximos de zero ou mesmo negativos, indicando maior pontualidade. À medida que o dia avança, os atrasos médios aumentam progressivamente, alcançando seus piores níveis no final da tarde e início da noite. Esse padrão é mais acentuado em EWR, onde os atrasos ultrapassam 25 minutos entre 17h e 20h, evidenciando maior sensibilidade ao acúmulo de atrasos e possíveis limitações de capacidade.\nComparativamente, JFK apresenta uma evolução mais gradual dos atrasos ao longo do dia, com crescimento significativo apenas a partir do início da tarde, enquanto LGA mantém níveis relativamente baixos até o meio da tarde, quando também passa a apresentar aumentos mais pronunciados. Ainda assim, LGA exibe picos relevantes em horários específicos, como no período noturno, indicando que, embora seja o aeroporto mais eficiente em média, não está imune a congestionamentos pontuais.\nDo ponto de vista estratégico, os resultados sugerem que EWR representa o principal gargalo operacional do sistema aeroportuário nova-iorquino, exigindo ações prioritárias de gestão de capacidade, revisão de slots e mitigação da propagação de atrasos ao longo do dia. Além disso, a forte dependência do horário reforça a importância de políticas operacionais voltadas para a proteção da malha nos períodos da manhã, uma vez que atrasos iniciais tendem a se amplificar nas horas subsequentes, afetando de forma sistêmica o desempenho ao longo do dia.\n3. A sazonalidade afeta a operação?\n\natraso_mes &lt;- flights |&gt;\n  filter(!is.na(arr_delay)) |&gt;\n  group_by(origin, month) |&gt;\n  summarise(\n    atraso_medio = mean(arr_delay)\n  )\n\nggplot(atraso_mes, aes(x = factor(month), y = atraso_medio)) +\n  geom_col(fill = \"lightgreen\") +\n  facet_grid(~origin) + \n  labs(\n    title = \"Atraso Médio por Mês\",\n    x = \"Mês\",\n    y = \"Atraso médio (minutos)\"\n  )\n\n\n\n\n\n\n\n\n\ndias_pt &lt;- c(\n  \"domingo\", \"segunda-feira\", \"terça-feira\",\n  \"quarta-feira\", \"quinta-feira\", \"sexta-feira\", \"sábado\"\n)\n\natraso_dia &lt;- flights |&gt;\n  mutate(\n    day_of_week = wday(\n      time_hour,\n      label = TRUE,\n      abbr = FALSE,\n      locale = \"Portuguese_Brazil.utf8\"\n    ),\n    day_of_week = factor(day_of_week, levels = dias_pt)\n  ) |&gt;\n  filter(!is.na(arr_delay)) |&gt;\n  group_by(origin, day_of_week) |&gt;\n  summarise(atraso_medio = mean(arr_delay), .groups = \"drop\")\n\nggplot(atraso_dia, aes(x = day_of_week, y = atraso_medio)) +\n  geom_col(fill = \"plum\") +\n  facet_grid(~origin) +\n  labs(\n    title = \"Atraso Médio por Dia da Semana\",\n    x = \"Dia da semana\",\n    y = \"Atraso médio (minutos)\"\n  )\n\n\n\n\n\n\n\n\nOs gráficos evidenciam um padrão claro de sazonalidade tanto ao longo da semana quanto ao longo do ano, com diferenças consistentes entre as origens. Em termos semanais, EWR apresenta atrasos médios sistematicamente mais elevados e maior variabilidade, sugerindo maior sensibilidade a congestionamentos operacionais, especialmente em dias úteis de maior demanda; JFK mostra atrasos médios mais moderados e estáveis, enquanto LGA apresenta comportamento intermediário, com alguns dias específicos concentrando picos de atraso. No recorte mensal, observa-se um efeito sazonal pronunciado: meses associados a maior demanda e condições meteorológicas adversas (verão e inverno) concentram os maiores atrasos médios, sobretudo em EWR e JFK, enquanto meses de transição tendem a apresentar desempenho operacional melhor. Em conjunto, os resultados indicam que a pontualidade é fortemente influenciada por fatores estruturais do aeroporto e por sazonalidade temporal, reforçando a importância de planejamento operacional diferenciado por origem, dia da semana e época do ano.\n4. Como as condições meteorológicas impactam os voos?\nVamos aprofundar essa análise, olhando para as condições meteorológicas nas rotas que apresentam maior atraso médio na chegada.\n\nrotas_criticas &lt;- gargalos_rotas |&gt; \n  slice_max(atraso_medio, n = 10) |&gt;\n  select(origin, dest)\n\n# Filtrar voos apenas dessas rotas\nflights_rotas_criticas &lt;- flights |&gt; \n  semi_join(rotas_criticas, by = c(\"origin\", \"dest\"))\n\n# Cruzar com dados meteorológicos\nflights_weather &lt;- flights_rotas_criticas |&gt; \n  left_join(\n    weather,\n    by = c(\"origin\", \"time_hour\")\n  )\n\n# Resumo descritivo das condições meteorológicas nas rotas críticas\nresumo_meteo &lt;- flights_weather |&gt; \n  summarise(\n    temp_media = mean(temp, na.rm = TRUE),\n    vento_medio = mean(wind_speed, na.rm = TRUE),\n    visibilidade_media = mean(visib, na.rm = TRUE),\n    precipitacao_media = mean(precip, na.rm = TRUE),\n    atraso_medio = mean(arr_delay, na.rm = TRUE)\n  )\n\nresumo_meteo_origin_dest &lt;- flights_weather |&gt; \n  group_by(origin, dest) |&gt; \n  summarise(\n    temp_media = mean(temp, na.rm = TRUE),\n    vento_medio = mean(wind_speed, na.rm = TRUE),\n    visibilidade_media = mean(visib, na.rm = TRUE),\n    precipitacao_media = mean(precip, na.rm = TRUE),\n    atraso_medio = mean(arr_delay, na.rm = TRUE)\n  )\n\nA tabela abaixo mostra as estatísticas descritivas gerais das condições meteorológicas nos voos das rotas com maior atraso.\n\n\n\n\n\ntemp_media\nvento_medio\nvisibilidade_media\nprecipitacao_media\natraso_medio\n\n\n\n\n56.67704\n10.31411\n9.124761\n0.0067495\n27.65729\n\n\n\n\n\nA tabela abaixo segmenta a análise por rota.\n\n\n\n\n\norigin\ndest\ntemp_media\nvento_medio\nvisibilidade_media\nprecipitacao_media\natraso_medio\n\n\n\n\nEWR\nDAY\n56.81000\n10.154568\n8.979167\n0.0091667\n24.27273\n\n\nEWR\nDCA\n56.75886\n9.552070\n9.274611\n0.0073057\n26.81111\n\n\nEWR\nGRR\n54.07631\n9.896708\n8.903846\n0.0032308\n28.03175\n\n\nEWR\nGSO\n54.49258\n9.526560\n8.971649\n0.0032990\n22.38144\n\n\nEWR\nMEM\n58.50459\n11.180514\n9.252294\n0.0146789\n20.93814\n\n\nEWR\nMKE\n55.07385\n9.304597\n9.181624\n0.0038462\n23.02655\n\n\nEWR\nPWM\n51.36543\n10.389899\n8.757143\n0.0034286\n20.37313\n\n\nEWR\nRIC\n58.71102\n9.793373\n8.848640\n0.0089116\n39.04138\n\n\nJFK\nCLE\n58.45486\n13.233970\n9.785714\n0.0012857\n21.38571\n\n\nJFK\nCMH\n60.78457\n12.576381\n9.346429\n0.0062857\n49.95312\n\n\n\n\n\nOs resultados indicam que os maiores atrasos médios observados nas rotas analisadas não estão associados, em geral, a condições meteorológicas adversas. As rotas com pior desempenho operacional apresentam, em média, temperaturas amenas, boa visibilidade, baixos níveis de precipitação e ventos moderados. Ainda assim, os atrasos médios são elevados, o que sugere que fatores climáticos exercem papel secundário na explicação dos gargalos identificados, atuando mais como agravantes pontuais do que como causa estrutural dos problemas.\nA análise por rota revela que os principais gargalos estão concentrados em poucos corredores específicos, com destaque para rotas partindo de Newark (EWR) e, em menor grau, de JFK. Algumas rotas, como JFK–CMH e EWR–RIC, apresentam atrasos médios persistentemente altos mesmo sob condições climáticas favoráveis, indicando ineficiências operacionais recorrentes, possivelmente relacionadas à gestão de slots, congestionamento aeroportuário ou propagação de atrasos ao longo do dia.\nDo ponto de vista estratégico, os achados sugerem que ações voltadas exclusivamente à mitigação de impactos climáticos terão efeito limitado na redução dos atrasos. Medidas focadas em melhoria de processos operacionais, aumento de resiliência da malha aérea e priorização de rotas cronicamente problemáticas tendem a gerar maior impacto. Em especial, o aeroporto de EWR emerge como um ponto crítico da operação, demandando atenção prioritária em iniciativas de planejamento, alocação de recursos e revisão de capacidade.\nRessalta-se que esta análise é descritiva e não estabelece relações causais, sendo possível que eventos meteorológicos extremos, ainda que raros, tenham impactos desproporcionais não capturados pela média.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Análise Descritiva de Dados</span>"
    ]
  },
  {
    "objectID": "01_analise_descritiva.html#referências-e-materiais-complementares",
    "href": "01_analise_descritiva.html#referências-e-materiais-complementares",
    "title": "1  Análise Descritiva de Dados",
    "section": "1.4 Referências e Materiais Complementares",
    "text": "1.4 Referências e Materiais Complementares\nO site Data to Viz é uma referência amplamente utilizada para apoiar a escolha adequada de visualizações gráficas em função do tipo de dado e do objetivo analítico. A plataforma organiza os principais tipos de gráficos de forma sistemática, auxiliando o analista a tomar decisões informadas sobre como representar informações de maneira clara e eficaz.\nAlém de apresentar uma ampla galeria de visualizações — como gráficos de barras, dispersão, linhas, áreas, mapas e outras variações — o Data to Viz oferece exemplos práticos e orientações conceituais que ajudam a compreender as vantagens, limitações e contextos de uso de cada gráfico. O material também aborda boas práticas de visualização, incluindo aspectos de legibilidade, interpretação correta e comunicação responsável dos dados, tornando-se um complemento natural aos conceitos discutidos neste capítulo.\nComo leitura complementar, recomenda-se o livro Storytelling com Dados: Um guia sobre visualização de dados para profissionais de negócios, de Cole Nussbaumer Knaflic. A obra enfatiza a importância de estruturar narrativas claras a partir de dados, destacando como escolhas visuais, foco narrativo e contextualização adequada podem transformar análises técnicas em mensagens acionáveis para tomada de decisão. Em particular, o livro aprofunda aspectos de comunicação, hierarquia visual e redução de ruído gráfico, reforçando a ideia de que visualização de dados não é apenas uma ferramenta analítica, mas também um instrumento estratégico de comunicação.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Análise Descritiva de Dados</span>"
    ]
  },
  {
    "objectID": "02_classificacao_manutencao_preventiva.html",
    "href": "02_classificacao_manutencao_preventiva.html",
    "title": "2  Análise de Manutenção Preditiva",
    "section": "",
    "text": "2.1 Configuração e Importação de Dados\nEste case aborda a análise de dados e construção de modelos de classificação para um problema de Manutenção Preditiva. O objetivo é prever se um equipamento apresentará falha (Target) com base em sensores operacionais.\nPrimeiro, importamos as bibliotecas necessárias e carregamos o dataset, predictive_maintainance que está relacionado à manutenção preditiva em um ambiente industrial. Cada linha representa uma observação de um equipamento, com várias variáveis registradas:\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nCarregamento do dataset (ajuste o caminho conforme sua máquina).\ndata = pd.read_csv('data/predictive_maintenance.csv')\ndata.head(10)\nUDI\nProduct ID\nType\nAir temperature [K]\nProcess temperature [K]\nRotational speed [rpm]\nTorque [Nm]\nTool wear [min]\nTarget\nFailure Type\n\n\n\n\n1\nM14860\nM\n298.1\n308.6\n1551\n42.8\n0\n0\nNo Failure\n\n\n2\nL47181\nL\n298.2\n308.7\n1408\n46.3\n3\n0\nNo Failure\n\n\n3\nL47182\nL\n298.1\n308.5\n1498\n49.4\n5\n0\nNo Failure\n\n\n4\nL47183\nL\n298.2\n308.6\n1433\n39.5\n7\n0\nNo Failure\n\n\n5\nL47184\nL\n298.2\n308.7\n1408\n40.0\n9\n0\nNo Failure\n\n\n6\nM14865\nM\n298.1\n308.6\n1425\n41.9\n11\n0\nNo Failure",
    "crumbs": [
      "Classificação",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise de Manutenção Preditiva</span>"
    ]
  },
  {
    "objectID": "02_classificacao_manutencao_preventiva.html#configuração-e-importação-de-dados",
    "href": "02_classificacao_manutencao_preventiva.html#configuração-e-importação-de-dados",
    "title": "2  Análise de Manutenção Preditiva",
    "section": "",
    "text": "UDI: Identificador único para cada observação.\nProduct ID: Identificador do produto associado à observação.\nType: Tipo do produto ou equipamento.\nAir temperature [K]: Temperatura do ar em Kelvin durante a operação.\nProcess temperature [K]: Temperatura do processo em Kelvin durante a operação.\nRotational speed [rpm]: Velocidade de rotação em rotações por minuto (RPM).\nTorque [Nm]: Torque aplicado durante o processo, medido em Newton-metros (Nm).\nTool wear [min]: Tempo de desgaste da ferramenta, em minutos.\nTarget: Variável alvo, indicando se ocorreu alguma falha ou não.\nFailure Type: Tipo de falha, se houver.",
    "crumbs": [
      "Classificação",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise de Manutenção Preditiva</span>"
    ]
  },
  {
    "objectID": "02_classificacao_manutencao_preventiva.html#avaliação-inicial-e-análise-descritiva",
    "href": "02_classificacao_manutencao_preventiva.html#avaliação-inicial-e-análise-descritiva",
    "title": "2  Análise de Manutenção Preditiva",
    "section": "2.2 Avaliação Inicial e Análise Descritiva",
    "text": "2.2 Avaliação Inicial e Análise Descritiva\nVamos entender o tamanho da base, a presença de valores nulos e a distribuição da variável alvo.\n\nprint(\"Número de observações:\", data.shape[0])\n\nNúmero de observações: 10000\n\nprint(\"Número de variáveis:\", data.shape[1])\n\nNúmero de variáveis: 10\n\n# Checagem de valores faltantes\nprint(\"\\nValores faltantes no dataset:\\n\", data.isnull().sum())\n\n\nValores faltantes no dataset:\n UDI                        0\nProduct ID                 0\nType                       0\nAir temperature [K]        0\nProcess temperature [K]    0\nRotational speed [rpm]     0\nTorque [Nm]                0\nTool wear [min]            0\nTarget                     0\nFailure Type               0\ndtype: int64\n\n# Checagem de duplicatas\nprint(\"\\nObservações duplicadas no dataset:\", data.duplicated().sum())\n\n\nObservações duplicadas no dataset: 0",
    "crumbs": [
      "Classificação",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise de Manutenção Preditiva</span>"
    ]
  },
  {
    "objectID": "02_classificacao_manutencao_preventiva.html#análise-descritiva",
    "href": "02_classificacao_manutencao_preventiva.html#análise-descritiva",
    "title": "2  Análise de Manutenção Preditiva",
    "section": "2.3 Análise Descritiva",
    "text": "2.3 Análise Descritiva\nPrimeiramente, avaliamos a frequencia da variável alvo.\n\n# Frequência da variável Target\ntarget_counts = data['Target'].value_counts()\ntarget_percentage = data['Target'].value_counts(normalize=True) * 100\nprint(\"\\nFrequência da variável Target:\\n\", target_counts)\n\n\nFrequência da variável Target:\n Target\n0    9661\n1     339\nName: count, dtype: int64\n\nprint(\"\\nPorcentagem da variável Target:\\n\", target_percentage)\n\n\nPorcentagem da variável Target:\n Target\n0    96.61\n1     3.39\nName: proportion, dtype: float64\n\n\nFrequência das variáveis categóricas.\n\n# Frequência da variável Type\nprint(\"Frequência da variável Type:\\n\", data['Type'].value_counts())\n\nFrequência da variável Type:\n Type\nL    6000\nM    2997\nH    1003\nName: count, dtype: int64\n\nprint(\"\\nFrequência da variável Type:\\n\", data['Failure Type'].value_counts())\n\n\nFrequência da variável Type:\n Failure Type\nNo Failure                  9652\nHeat Dissipation Failure     112\nPower Failure                 95\nOverstrain Failure            78\nTool Wear Failure             45\nRandom Failures               18\nName: count, dtype: int64\n\n\nEstatísticas descritivas das variáveis numéricas.\n\nprint(\"Estatísticas descritivas das variáveis numéricas:\\n\", data.describe())\n\nEstatísticas descritivas das variáveis numéricas:\n                UDI  Air temperature [K]  ...  Tool wear [min]        Target\ncount  10000.00000         10000.000000  ...     10000.000000  10000.000000\nmean    5000.50000           300.004930  ...       107.951000      0.033900\nstd     2886.89568             2.000259  ...        63.654147      0.180981\nmin        1.00000           295.300000  ...         0.000000      0.000000\n25%     2500.75000           298.300000  ...        53.000000      0.000000\n50%     5000.50000           300.100000  ...       108.000000      0.000000\n75%     7500.25000           301.500000  ...       162.000000      0.000000\nmax    10000.00000           304.500000  ...       253.000000      1.000000\n\n[8 rows x 7 columns]\n\n\n\n2.3.1 Relação das Variáveis com a Target\nA matriz de correlação nos ajuda a identificar quais variáveis numéricas possuem maior relação com a ocorrência de falhas.\n\nnumeric_data = data.select_dtypes(include=np.number)\ncorrelation_matrix = numeric_data.corr()\n\nplt.figure(figsize=(12, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\nplt.title('Matriz de Correlação')\nplt.show()\n\n\n\n\n\n\n\n\nRelação entre a variável Type e a variável Target.\n\nmedia_target_por_type = data.groupby('Type')['Target'].mean()\nprint(\"Média de Target por classe de Type:\\n\", media_target_por_type)\n\nMédia de Target por classe de Type:\n Type\nH    0.020937\nL    0.039167\nM    0.027694\nName: Target, dtype: float64\n\nmedia_target_por_type = data.groupby('Failure Type')['Target'].mean()\nprint(\"\\n\\nMédia de Target por classe de Failure Type:\\n\", media_target_por_type)\n\n\n\nMédia de Target por classe de Failure Type:\n Failure Type\nHeat Dissipation Failure    1.000000\nNo Failure                  0.000932\nOverstrain Failure          1.000000\nPower Failure               1.000000\nRandom Failures             0.000000\nTool Wear Failure           1.000000\nName: Target, dtype: float64",
    "crumbs": [
      "Classificação",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise de Manutenção Preditiva</span>"
    ]
  },
  {
    "objectID": "02_classificacao_manutencao_preventiva.html#construção-do-modelo-preditivo",
    "href": "02_classificacao_manutencao_preventiva.html#construção-do-modelo-preditivo",
    "title": "2  Análise de Manutenção Preditiva",
    "section": "2.4 Construção do Modelo Preditivo",
    "text": "2.4 Construção do Modelo Preditivo\n\n2.4.1 Preparação dos Dados\nPara o modelo, precisamos remover identificadores e transformar variáveis categóricas (como o tipo do produto) em variáveis numéricas (dummies).\nRemovendo identificadores e colunas de diagnóstico posterior\n\ndata_model = data.drop(['UDI', 'Failure Type', 'Product ID'], axis=1)\n\nTransformando variáveis categóricas em dummies\n\ndata_model = pd.get_dummies(data_model, drop_first=True)\n\nDefinição das variávei explicativas (features) e da variável alvo (target).\n\n# Definição de X e y\nvariaveis_explicativas = ['Air temperature [K]', 'Process temperature [K]', \n                          'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\nX = data_model[variaveis_explicativas]\ny = data_model['Target']\n\nDivisão em treino (85%) e validação (15%).\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n\n\n\n2.4.2 Treinamento e Comparação de Modelos\nVamos testar quatro algoritmos diferentes: Regressão Logística, Random Forest, KNN e Redes Neurais.\n\n# Inicialização dos modelos\nmodelos = {\n    \"Regressão Logística\": LogisticRegression(),\n    \"Random Forest\": RandomForestClassifier(random_state=42),\n    \"KNN\": KNeighborsClassifier(),\n    \"Redes Neurais\": MLPClassifier(random_state=42)\n}\n\n# Função de avaliação para automatizar o processo\ndef avaliar_modelo(nome, model, X_train, y_train, X_val, y_val):\n    # O modelo é treinado aqui\n    model.fit(X_train, y_train)\n    # Predições\n    y_pred_train = model.predict(X_train)\n    y_pred_val = model.predict(X_val)\n    \n    # Cálculo das métricas de Acurácia\n    acuracia_train = accuracy_score(y_train, y_pred_train)\n    acuracia_val = accuracy_score(y_val, y_pred_val)\n    \n    # Matrizes de Confusão\n    cm_train = confusion_matrix(y_train, y_pred_train)\n    cm_val = confusion_matrix(y_val, y_pred_val)\n    \n    # Cálculo de % de Falsos Positivos e Negativos sobre o TOTAL da amostra\n    # (Refletindo a lógica exata do seu notebook original)\n    fp_train = (cm_train[0, 1] / (sum(cm_train[0]) + sum(cm_train[1])))\n    fn_train = (cm_train[1, 0] / (sum(cm_train[0]) + sum(cm_train[1])))\n    \n    fp_val = (cm_val[0, 1] / (sum(cm_val[0]) + sum(cm_val[1])))\n    fn_val = (cm_val[1, 0] / (sum(cm_val[0]) + sum(cm_val[1])))\n    \n    # Saída formatada para a aula\n    print(f\"--- {nome} ---\")\n    print(f\"Acurácia no treino: {acuracia_train:.4f}\")\n    print(f\"Acurácia na validação: {acuracia_val:.4f}\")\n    print(f\"Matriz de Confusão no treino:\\n{cm_train}\")\n    print(f\"Matriz de Confusão na validação:\\n{cm_val}\")\n    print(f\"% de Falsos Positivos no treino: {fp_train:.4%}\")\n    print(f\"% de Falsos Negativos no treino: {fn_train:.4%}\")\n    print(f\"% de Falsos Positivos na validação: {fp_val:.4%}\")\n    print(f\"% de Falsos Negativos na validação: {fn_val:.4%}\")\n    print(\"\\n\" + \"=\"*30 + \"\\n\")\n\nfor nome, modelo in modelos.items():\n    avaliar_modelo(nome, modelo, X_train, y_train, X_val, y_val)\n\n--- Regressão Logística ---\nAcurácia no treino: 0.9699\nAcurácia na validação: 0.9707\nMatriz de Confusão no treino:\n[[8182   26]\n [ 230   62]]\nMatriz de Confusão na validação:\n[[1446    7]\n [  37   10]]\n% de Falsos Positivos no treino: 0.3059%\n% de Falsos Negativos no treino: 2.7059%\n% de Falsos Positivos na validação: 0.4667%\n% de Falsos Negativos na validação: 2.4667%\n\n==============================\n\n--- Random Forest ---\nAcurácia no treino: 1.0000\nAcurácia na validação: 0.9867\nMatriz de Confusão no treino:\n[[8208    0]\n [   0  292]]\nMatriz de Confusão na validação:\n[[1449    4]\n [  16   31]]\n% de Falsos Positivos no treino: 0.0000%\n% de Falsos Negativos no treino: 0.0000%\n% de Falsos Positivos na validação: 0.2667%\n% de Falsos Negativos na validação: 1.0667%\n\n==============================\n\n--- KNN ---\nAcurácia no treino: 0.9738\nAcurácia na validação: 0.9700\nMatriz de Confusão no treino:\n[[8189   19]\n [ 204   88]]\nMatriz de Confusão na validação:\n[[1448    5]\n [  40    7]]\n% de Falsos Positivos no treino: 0.2235%\n% de Falsos Negativos no treino: 2.4000%\n% de Falsos Positivos na validação: 0.3333%\n% de Falsos Negativos na validação: 2.6667%\n\n==============================\n\n--- Redes Neurais ---\nAcurácia no treino: 0.9656\nAcurácia na validação: 0.9687\nMatriz de Confusão no treino:\n[[8208    0]\n [ 292    0]]\nMatriz de Confusão na validação:\n[[1453    0]\n [  47    0]]\n% de Falsos Positivos no treino: 0.0000%\n% de Falsos Negativos no treino: 3.4353%\n% de Falsos Positivos na validação: 0.0000%\n% de Falsos Negativos na validação: 3.1333%\n\n==============================",
    "crumbs": [
      "Classificação",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise de Manutenção Preditiva</span>"
    ]
  },
  {
    "objectID": "02_classificacao_manutencao_preventiva.html#análise-de-performance-por-percentil",
    "href": "02_classificacao_manutencao_preventiva.html#análise-de-performance-por-percentil",
    "title": "2  Análise de Manutenção Preditiva",
    "section": "2.5 Análise de Performance por Percentil",
    "text": "2.5 Análise de Performance por Percentil\nCriando um dataframe para consolidar as probabilidades.\n\ndf_probabilidades = pd.DataFrame({'Target_Real': y_val})\n\nfor nome, modelo in modelos.items():\n# Treinando (garantindo que todos estão fitados)\n  modelo.fit(X_train, y_train)\n\n  # Extraindo a probabilidade da classe 1 (falha)\n  # Nota: Alguns modelos podem não ter predict_proba, mas os selecionados possuem.\n  df_probabilidades[f'Prob_{nome}'] = modelo.predict_proba(X_val)[:, 1]\n  print(\"Primeras linhas do consolidado de probabilidades:\")\n\nMLPClassifier(random_state=42)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.MLPClassifier?Documentation for MLPClassifieriFitted\n        \n            \n                Parameters\n                \n\n\n\n\n\n\n\n\n\nhidden_layer_sizes hidden_layer_sizes: array-like of shape(n_layers - 2,), default=(100,)\n\nThe ith element represents the number of neurons in the ith\nhidden layer.\n(100,)\n\n\n\nactivation activation: {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n\nActivation function for the hidden layer.\n\n- 'identity', no-op activation, useful to implement linear bottleneck,\nreturns f(x) = x\n\n- 'logistic', the logistic sigmoid function,\nreturns f(x) = 1 / (1 + exp(-x)).\n\n- 'tanh', the hyperbolic tan function,\nreturns f(x) = tanh(x).\n\n- 'relu', the rectified linear unit function,\nreturns f(x) = max(0, x)\n'relu'\n\n\n\nsolver solver: {'lbfgs', 'sgd', 'adam'}, default='adam'\n\nThe solver for weight optimization.\n\n- 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n\n- 'sgd' refers to stochastic gradient descent.\n\n- 'adam' refers to a stochastic gradient-based optimizer proposed\nby Kingma, Diederik, and Jimmy Ba\n\nFor a comparison between Adam optimizer and SGD, see\n:ref:`sphx_glr_auto_examples_neural_networks_plot_mlp_training_curves.py`.\n\nNote: The default solver 'adam' works pretty well on relatively\nlarge datasets (with thousands of training samples or more) in terms of\nboth training time and validation score.\nFor small datasets, however, 'lbfgs' can converge faster and perform\nbetter.\n'adam'\n\n\n\nalpha alpha: float, default=0.0001\n\nStrength of the L2 regularization term. The L2 regularization term\nis divided by the sample size when added to the loss.\n\nFor an example usage and visualization of varying regularization, see\n:ref:`sphx_glr_auto_examples_neural_networks_plot_mlp_alpha.py`.\n0.0001\n\n\n\nbatch_size batch_size: int, default='auto'\n\nSize of minibatches for stochastic optimizers.\nIf the solver is 'lbfgs', the classifier will not use minibatch.\nWhen set to \"auto\", `batch_size=min(200, n_samples)`.\n'auto'\n\n\n\nlearning_rate learning_rate: {'constant', 'invscaling', 'adaptive'}, default='constant'\n\nLearning rate schedule for weight updates.\n\n- 'constant' is a constant learning rate given by\n'learning_rate_init'.\n\n- 'invscaling' gradually decreases the learning rate at each\ntime step 't' using an inverse scaling exponent of 'power_t'.\neffective_learning_rate = learning_rate_init / pow(t, power_t)\n\n- 'adaptive' keeps the learning rate constant to\n'learning_rate_init' as long as training loss keeps decreasing.\nEach time two consecutive epochs fail to decrease training loss by at\nleast tol, or fail to increase validation score by at least tol if\n'early_stopping' is on, the current learning rate is divided by 5.\n\nOnly used when ``solver='sgd'``.\n'constant'\n\n\n\nlearning_rate_init learning_rate_init: float, default=0.001\n\nThe initial learning rate used. It controls the step-size\nin updating the weights. Only used when solver='sgd' or 'adam'.\n0.001\n\n\n\npower_t power_t: float, default=0.5\n\nThe exponent for inverse scaling learning rate.\nIt is used in updating effective learning rate when the learning_rate\nis set to 'invscaling'. Only used when solver='sgd'.\n0.5\n\n\n\nmax_iter max_iter: int, default=200\n\nMaximum number of iterations. The solver iterates until convergence\n(determined by 'tol') or this number of iterations. For stochastic\nsolvers ('sgd', 'adam'), note that this determines the number of epochs\n(how many times each data point will be used), not the number of\ngradient steps.\n200\n\n\n\nshuffle shuffle: bool, default=True\n\nWhether to shuffle samples in each iteration. Only used when\nsolver='sgd' or 'adam'.\nTrue\n\n\n\nrandom_state random_state: int, RandomState instance, default=None\n\nDetermines random number generation for weights and bias\ninitialization, train-test split if early stopping is used, and batch\nsampling when solver='sgd' or 'adam'.\nPass an int for reproducible results across multiple function calls.\nSee :term:`Glossary `.\n42\n\n\n\ntol tol: float, default=1e-4\n\nTolerance for the optimization. When the loss or score is not improving\nby at least ``tol`` for ``n_iter_no_change`` consecutive iterations,\nunless ``learning_rate`` is set to 'adaptive', convergence is\nconsidered to be reached and training stops.\n0.0001\n\n\n\nverbose verbose: bool, default=False\n\nWhether to print progress messages to stdout.\nFalse\n\n\n\nwarm_start warm_start: bool, default=False\n\nWhen set to True, reuse the solution of the previous\ncall to fit as initialization, otherwise, just erase the\nprevious solution. See :term:`the Glossary `.\nFalse\n\n\n\nmomentum momentum: float, default=0.9\n\nMomentum for gradient descent update. Should be between 0 and 1. Only\nused when solver='sgd'.\n0.9\n\n\n\nnesterovs_momentum nesterovs_momentum: bool, default=True\n\nWhether to use Nesterov's momentum. Only used when solver='sgd' and\nmomentum &gt; 0.\nTrue\n\n\n\nearly_stopping early_stopping: bool, default=False\n\nWhether to use early stopping to terminate training when validation\nscore is not improving. If set to True, it will automatically set\naside ``validation_fraction`` of training data as validation and\nterminate training when validation score is not improving by at least\n``tol`` for ``n_iter_no_change`` consecutive epochs. The split is\nstratified, except in a multilabel setting.\nIf early stopping is False, then the training stops when the training\nloss does not improve by more than ``tol`` for ``n_iter_no_change``\nconsecutive passes over the training set.\nOnly effective when solver='sgd' or 'adam'.\nFalse\n\n\n\nvalidation_fraction validation_fraction: float, default=0.1\n\nThe proportion of training data to set aside as validation set for\nearly stopping. Must be between 0 and 1.\nOnly used if early_stopping is True.\n0.1\n\n\n\nbeta_1 beta_1: float, default=0.9\n\nExponential decay rate for estimates of first moment vector in adam,\nshould be in [0, 1). Only used when solver='adam'.\n0.9\n\n\n\nbeta_2 beta_2: float, default=0.999\n\nExponential decay rate for estimates of second moment vector in adam,\nshould be in [0, 1). Only used when solver='adam'.\n0.999\n\n\n\nepsilon epsilon: float, default=1e-8\n\nValue for numerical stability in adam. Only used when solver='adam'.\n1e-08\n\n\n\nn_iter_no_change n_iter_no_change: int, default=10\n\nMaximum number of epochs to not meet ``tol`` improvement.\nOnly effective when solver='sgd' or 'adam'.\n\n.. versionadded:: 0.20\n10\n\n\n\nmax_fun max_fun: int, default=15000\n\nOnly used when solver='lbfgs'. Maximum number of loss function calls.\nThe solver iterates until convergence (determined by 'tol'), number\nof iterations reaches max_iter, or this number of loss function calls.\nNote that number of loss function calls will be greater than or equal\nto the number of iterations for the `MLPClassifier`.\n\n.. versionadded:: 0.22\n15000\n\n\n\n\n            \n        \n    \n\n\n\nprint(df_probabilidades.head())\n\n\n\n\n\n\n\nTarget_Real\nProb_Regressão Logística\nProb_Random Forest\nProb_KNN\nProb_Redes Neurais\n\n\n\n\n6252\n0\n0.0123673\n0.00\n0.0\n7.00e-07\n\n\n4684\n1\n0.0255143\n0.00\n0.0\n1.20e-06\n\n\n1731\n0\n0.0135146\n0.00\n0.0\n7.00e-07\n\n\n4742\n0\n0.0032589\n0.00\n0.0\n4.00e-07\n\n\n4521\n0\n0.0242423\n0.00\n0.0\n0.00e+00\n\n\n6340\n1\n0.0479644\n0.36\n0.2\n2.86e-05\n\n\n\n\n\nAgora, vamos calcular a taxa de falha real para cada decil de probabilidade de cada modelo. Um modelo “bom de negócio” deve concentrar quase todas as falhas nos primeiros decis (maior probabilidade).\n\ndef calcular_performance_decil(df, col_prob, col_target, nome_modelo):\n  # Criando os decis\n  df_temp = df[[col_target, col_prob]].copy()\n  # Usamos rank para lidar com probabilidades repetidas (comum no KNN e RF)\n  df_temp['Decil'] = pd.qcut(df_temp[col_prob].rank(method='first'), 10, labels=range(10, 0, -1))\n  # Agrupando por decil\n  performance = df_temp.groupby('Decil', observed=True).agg(\n      total_maquinas=(col_target, 'count'),\n      falhas_reais=(col_target, 'sum')\n  ).reset_index()\n  \n  performance['Taxa_Falha'] = performance['falhas_reais'] / performance['total_maquinas']\n  performance['Modelo'] = nome_modelo\n  return performance\n\nanalise_decis_completa = pd.concat([\ncalcular_performance_decil(df_probabilidades, f'Prob_{nome}', 'Target_Real', nome)\nfor nome in modelos.keys()\n])\n\nVisualização Comparativa\n\nplt.figure(figsize=(12, 6))\nsns.lineplot(data=analise_decis_completa, x='Decil', y='Taxa_Falha', hue='Modelo', marker='o')\nplt.title('Capacidade de Ordenamento: Taxa de Falha Real por Decil')\nplt.ylabel('Taxa de Falha Real (Hit Rate)')\nplt.xlabel('Decil de Risco (1 = Mais Provável)')\nplt.gca().invert_xaxis() # Inverter para o Decil 10 (maior risco) ficar na esquerda\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()",
    "crumbs": [
      "Classificação",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise de Manutenção Preditiva</span>"
    ]
  },
  {
    "objectID": "02_classificacao_manutencao_preventiva.html#impacto-financeiro-e-seleção-do-modelo",
    "href": "02_classificacao_manutencao_preventiva.html#impacto-financeiro-e-seleção-do-modelo",
    "title": "2  Análise de Manutenção Preditiva",
    "section": "2.6 Impacto Financeiro e Seleção do Modelo",
    "text": "2.6 Impacto Financeiro e Seleção do Modelo\nA escolha do “Melhor Modelo” depende do custo do erro. Vamos calcular o impacto financeiro considerando que uma Quebra (Falso Negativo) custa 20x mais que uma Inspeção (Falso Positivo).\n\ndef avaliar_custo_modelo(df_probs, col_target, modelos_dict, custo_fp=500, custo_fn=10000):\n  relatorio_custos = []\n  \n  for nome in modelos_dict.keys():\n    # Usando o corte padrão de 0.5 para comparação\n    preds = (df_probs[f'Prob_{nome}'] &gt;= 0.5).astype(int)\n    cm = confusion_matrix(df_probs[col_target], preds)\n    \n    fp = cm[0, 1]\n    fn = cm[1, 0]\n    custo_total = (fp * custo_fp) + (fn * custo_fn)\n    \n    relatorio_custos.append({\n        'Modelo': nome,\n        'Falsos Positivos': fp,\n        'Falsos Negativos': fn,\n        'Custo Total (R$)': custo_total\n    })\n\n  return pd.DataFrame(relatorio_custos).sort_values('Custo Total (R$)')\n\ndf_custos = avaliar_custo_modelo(df_probabilidades, 'Target_Real', modelos)\nprint(\"Relatório de Impacto Financeiro (Corte 0.50):\")\n\nRelatório de Impacto Financeiro (Corte 0.50):\n\nprint(df_custos)\n\n                Modelo  Falsos Positivos  Falsos Negativos  Custo Total (R$)\n1        Random Forest                 4                16            162000\n0  Regressão Logística                 7                37            373500\n2                  KNN                 5                40            402500\n3        Redes Neurais                 0                47            470000\n\n\n\n\n\n\n\n\nModelo\nFalsos Positivos\nFalsos Negativos\nCusto Total (R$)\n\n\n\n\n1\nRandom Forest\n4\n16\n162000\n\n\n0\nRegressão Logística\n7\n37\n373500\n\n\n2\nKNN\n5\n40\n402500\n\n\n3\nRedes Neurais\n0\n47\n470000\n\n\n\n\n\nAo atribuirmos valores monetários aos erros — R$ 500,00 para uma inspeção desnecessária (FP) e R$ 10.000,00 para uma quebra catastrófica (FN) — a hierarquia dos modelos muda:\n\nO modelo vencedpr: Random Forest\n\nCom um custo total de R$ 162.000, este modelo é o mais eficiente para a operação.\nSua vantagem reside na baixa taxa de Falsos Negativos (16), provando que cada falha evitada compensa financeiramente até 20 inspeções preventivas sem falha.\nO Random Forest conseguiu o melhor equilíbrio entre sensibilidade e precisão.\n\nA Armadilha das Redes Neurais (O “Modelo Limpinho”)\n\nEmbora tenha apresentado 0 Falsos Positivos (precisão perfeita nos alarmes - não “jogar dinheiro fora” com inspeções inúteis), é o pior cenário financeiro (R$ 470.000).\nIsso demonstra que o conservadorismo extremo do modelo ignora muitas quebras reais (47 Falsos Negativos), custando caro para a operação.\n\n\nApesar de não “jogar dinheiro fora” com inspeções inúteis, ele é o pior modelo financeiramente (R$ 470.000).\nSer conservador demais e só “apontar o dedo” quando se tem certeza absoluta (zero FPs) pode custar uma fortuna em quebras não detectadas (47 Falsos Negativos). Precisão absoluta pode ser um péssimo negócio.\n\nRegressão Logística vs. KNN\n\nA Regressão Logística é R$ 29.000 mais barata que o KNN, pois capturou 3 falhas a mais, mesmo gerando 2 alarmes falsos adicionais.\n\n\nEm manutenção preditiva, preferimos modelos “barulhentos” (mais FPs) a modelos “míopes” (mais FNs). A precisão absoluta pode ser um péssimo negócio se o custo da omissão for elevado.",
    "crumbs": [
      "Classificação",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise de Manutenção Preditiva</span>"
    ]
  },
  {
    "objectID": "02_classificacao_manutencao_preventiva.html#próximos-passos",
    "href": "02_classificacao_manutencao_preventiva.html#próximos-passos",
    "title": "2  Análise de Manutenção Preditiva",
    "section": "2.7 Próximos Passos",
    "text": "2.7 Próximos Passos\nO modelo selecionado para implementação é a Random Forest. Como evolução desta análise, o próximo passo estratégico é:\n\nOtimização de Threshold: “Podemos ajustar o ponto de corte (threshold) da Random Forest para reduzir os 16 Falsos Negativos ainda mais, mesmo que o número de Falsos Positivos suba para 20 ou 30?”",
    "crumbs": [
      "Classificação",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise de Manutenção Preditiva</span>"
    ]
  }
]